{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a33004aa-8bfb-4709-a437-e0f141eaa283",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "\n",
    "Load the raw dataset, extract labels from filenames, resize images to 96x96 (from 96x103) so that they can be fed into a CNN, and save processed arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf000bb5-56e8-4f42-a41e-7e698fa7fe6a",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8f1b7a32-ce3a-4cf2-8049-6713615a99d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import glob, os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293acc5e-bef5-4620-b00b-863ce8efa02c",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 2 - Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c653960-388d-4280-924d-46b4ece18982",
   "metadata": {},
   "source": [
    "<a name='2.1'></a>\n",
    "### 2.1 - Image\n",
    "Loads a grayscale image and resizes it to 96x96."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "363a3559-48b3-4196-a104-f1a4f2e480aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    return cv2.resize(img, (96, 96))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f213dac-2539-46ed-8136-ee54110b3b1b",
   "metadata": {},
   "source": [
    "<a name='2.2'></a>\n",
    "### 2.2 - Labels  \n",
    "Extracts label information (subject ID, gender, side, finger) from filename. If the image is from an altered dataset, the filename format slightly differs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "921b936a-7c61-4707-be59-64822ff36470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_label(path, altered = True):\n",
    "    filename, _ = os.path.splitext(os.path.basename(img_path))\n",
    "    subject_id, etc = filename.split('__')\n",
    "    if altered:  gender, side, finger, _, _ = etc.split('_')\n",
    "    else:        gender, side, finger, _ = etc.split('_')\n",
    "\n",
    "    # Convert categorical info to integers\n",
    "    gender = 0 if gender == 'M' else 1\n",
    "    side = 0 if side =='Left' else 1\n",
    "\n",
    "    if finger == 'thumb':     finger = 0\n",
    "    elif finger == 'index':   finger = 1\n",
    "    elif finger == 'middle':  finger = 2\n",
    "    elif finger == 'ring':    finger = 3\n",
    "    elif finger == 'little':  finger = 4\n",
    "\n",
    "    return np.array([subject_id, gender, side, finger], dtype=np.uint16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00a04c2-f33d-42aa-920c-9574c977c04b",
   "metadata": {},
   "source": [
    "<a name='2.3'></a>\n",
    "### 2.3 - Dataset locations \n",
    "Different folders for real and altered images, categorized by difficulty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7b1d32c2-b8c3-44f6-bf30-50ab01a770d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = [\n",
    "    \"Real\",\n",
    "    \"Altered/Altered-Easy/\",\n",
    "    \"Altered/Altered-Medium/\",\n",
    "    \"Altered/Altered-Hard/\"\n",
    "]\n",
    "out_tag = [\"real\", \"easy\", \"medium\", \"hard\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a3ce1a-ed6e-4cad-9c12-7eb8ebfdeb5a",
   "metadata": {},
   "source": [
    "<a name='2.4'></a>\n",
    "### 2.4 - Loop through  \n",
    "For each folder:\n",
    " - Load and process each image\n",
    " - Extract corresponding labels\n",
    " - Save images and labels as .npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11315625-81c3-4f32-a8ec-bd1c7320e290",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_key, i_path in enumerate(img_dir):\n",
    "    img_list = sorted(glob.glob('dataset/raw/'+ i_path +'/*.BMP'))\n",
    "            \n",
    "    imgs = np.empty((len(img_list), 96, 96), dtype=np.uint8)\n",
    "    labels = np.empty((len(img_list), 4), dtype=np.uint16)\n",
    "\n",
    "    for i, img_path in enumerate(img_list):\n",
    "        imgs[i] = process_image(img_path)\n",
    "        labels[i] = process_label(img_path, i_key != 0)\n",
    "\n",
    "    np.save('dataset/processed/x_'+out_tag[i_key], imgs)\n",
    "    np.save('dataset/processed/y_'+out_tag[i_key], labels)\n",
    "    \n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.title(labels[0])\n",
    "    plt.imshow(imgs[0], cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
